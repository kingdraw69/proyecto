# -*- coding: utf-8 -*-
"""modelos

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19gnBAqCypD0S3-DmIurCDo6_qeAnrgmY

**PASOS**

Libreria y cargue de datos.

extraccion de caracteristicas y preprocesamiento de datos.

Preparacion de datos para el modelo (seleccion de caracteristicas, dividir los datos entrenamiento)

Entrenar el modelo(3 modelos)

Validacion del modelo.

Salvar el modelo seleccionado.
"""



#https://github.com/adiacla/bigdata/blob/master/DatosEmpresaChurn.csv

#1 #TRATAMIENTO DE DATOS
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib as jb
import csv
import seaborn as sns



import ipywidgets as widgets

from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

from sklearn.tree import DecisionTreeClassifier

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve,auc


from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict

# Cargar los datos

with open(r'C:\Users\ivane\Downloads\DatosEmpresaChurn.csv', 'r') as archivo:
    # Lee todo el contenido del archivo y lo almacena en una variable
    contenido = archivo.read()

df = pd.read_csv(contenido)

df



df.info()

#se retira de la columna ANTIG las comas, para poderlo combertir de object a float


df["ANTIG"]=df["ANTIG"].replace(',','.',regex=True)


df

"""indice Gini y ganancia de la informacion  """

#indice Gini(esta funcion de costo mide el grdo de inpureza) y ganancia de la informacion(para datos categoricos)

#pruning para quitar las  ramas inecesarias por que pdria tener un dobre ajuste

#arboles de decision

df["ANTIG"]=df["ANTIG"].astype(float)

df



df.info()

df.describe()

df.head(10)

df.isnull().sum()

df.columns=["SIN_NOMBRE","antiguo", "compras", "promedio", "categoría","comunicación_interna","compras_presenciales",
            "tasa", "Visitas", "días_sin_Q","Tasa_de_retorno","numero_Q", "retorno",
            "Resultado"]

df.info()

corr_matrix=df[['antiguo', 'compras', 'promedio', 'categoría', 'comunicación_interna',
       'compras_presenciales', 'tasa', 'Visitas', 'días_sin_Q',
       'Tasa_de_retorno', 'numero_Q',]].corr()

df.index = range(1, len(df) + 1)
df

# Eliminar la columna 'Unnamed: 0'
df.drop('SIN_NOMBRE', axis=1, inplace=True)

# Eliminar las columnas 'CATEG' y 'VISIT'
df.drop(['categoría', 'Visitas'], axis=1, inplace=True)

# Imprimir la información del DataFrame para verificar los cambios
print(df.info())

# Imputar los valores nulos si es necesario (no eliminaremos filas con valores nulos)
# Ejemplo de imputación para la columna 'DIASSINQ'
df['días_sin_Q'].fillna(df['días_sin_Q'].mean(), inplace=True)

# Graficar las características numéricas en pares
sns.pairplot(data=df, diag_kind='kde')
plt.show()



# Imprimir estadísticas descriptivas para características numéricas
print(df.describe())

# Imprimir las primeras filas del DataFrame para verificar los cambios
print(df.head())

# Graficar matriz de correlación
corr_matrix = df.corr()
fig, ax=plt.subplots(figsize=(10,10)) #SIEMPRE
colormap=sns.color_palette("BrBG",10)
sns.heatmap(corr_matrix, cmap=colormap, annot=True, fmt=".2f")
plt.title('Matriz de correlación')
plt.show()

columnas = df.select_dtypes(include='float').columns

fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 14))
axes = axes.flat

for i, columna in enumerate(columnas):
    sns.boxplot(x='Resultado', y=columna, data=df, hue='Resultado', ax=axes[i])
    axes[i].set_title(columna, fontsize=7, fontweight="bold")
    axes[i].tick_params(labelsize=6)
    axes[i].set_xlabel("")

fig.suptitle("Box Plot de todos los Feature", fontsize=10, fontweight="bold")

colors=np.where(df["Resultado"]==0,"green","red")
def angulo (x,y):
  fig=plt.figure(figsize=(9,10))
  ax=fig.add_subplot(projection='3d')
  ax.scatter(df["antiguo"],df["compras"],df["promedio"], c=colors, marker="*")
  ax.fontsize=5,
  ax.view_init(x,y)
  ax.set_xlabel("antiguo")
  ax.set_ylabel("compras")
  ax.set_zlabel("promedio")
  plt.show()


grafico=widgets.interact(angulo,x=[60,-90,-45,0,30,45,90], y=[60,-90,-45,30,0,30,45,90])

df.plot(kind='density', subplots=True, layout=(6,3), figsize=(12,12), sharex=False)

# Identificar filas con valores de "antiguo" mayores a 1500
indices_a_eliminar = df[df['antiguo'] > 1500].index

df=df.drop(indices_a_eliminar) #por ser irrelevante
df

# Eliminar las características "Antigüedad" y "Comunicación interna"
df = df.drop(["antiguo"], axis=1) #por la baja relacion con el dato a encontrar

df.info()



df.head()

columnas = df.select_dtypes(include='float').columns

fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 14))
axes = axes.flat

for i, columna in enumerate(columnas):
    sns.boxplot(x='Resultado', y=columna, data=df, hue='Resultado', ax=axes[i])
    axes[i].set_title(columna, fontsize=7, fontweight="bold")
    axes[i].tick_params(labelsize=6)
    axes[i].set_xlabel("")

fig.suptitle("Box Plot de todos los Feature", fontsize=10, fontweight="bold")

# Extraer las características "Compras" y "Promedio"
compras = df["compras"]
promedio = df["promedio"]

# Crear la gráfica de dispersión
plt.figure(figsize=(8, 6))
plt.scatter(compras, promedio, color='blue', alpha=0.5)
plt.title('Gráfica de dispersión entre Compras y Promedio')
plt.xlabel('Compras')
plt.ylabel('Promedio')
plt.grid(True)
plt.show()

df.plot(kind='density', subplots=True, layout=(6,3), figsize=(12,12), sharex=False)

df.columns=['COMP', 'PROM', 'COMINT', 'COMPPRES', 'RATE', 'DIASSINQ','TASARET', 'NUMQ', 'RETRE','Resultado']

# Dividir los datos en características (X) y etiquetas (y)
X = df.drop('Resultado', axis=1)
y = df['Resultado']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.8,random_state=454, stratify=df.Resultado)

# Imputar valores nulos en el conjunto de entrenamiento y prueba
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Escalar las características para que tengan media 0 y desviación estándar 1
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_test_scaled = scaler.transform(X_test_imputed)

# Inicializar los clasificadores
gnb = GaussianNB()
rfc = RandomForestClassifier(n_estimators=100, random_state=42)

# Entrenar el modelo Gaussian Naive Bayes
gnb.fit(X_train_scaled, y_train)

# Predecir en el conjunto de prueba y calcular la precisión
y_pred_gnb = gnb.predict(X_test_scaled)
accuracy_gnb = accuracy_score(y_test, y_pred_gnb)
print("Precisión del modelo Gaussian Naive Bayes:", accuracy_gnb)

# Entrenar el modelo Random Forest
rfc.fit(X_train_scaled, y_train)

# Predecir en el conjunto de prueba y calcular la precisión
y_pred_rfc = rfc.predict(X_test_scaled)
accuracy_rfc = accuracy_score(y_test, y_pred_rfc)
print("Precisión del modelo Random Forest:", accuracy_rfc)

# Inicializar el clasificador de árbol de decisión
dtc = DecisionTreeClassifier(random_state=42)

# Entrenar el modelo de árbol de decisión
dtc.fit(X_train_scaled, y_train)

# Predecir en el conjunto de prueba y calcular la precisión
y_pred_dtc = dtc.predict(X_test_scaled)
accuracy_dtc = accuracy_score(y_test, y_pred_dtc)
print("Precisión del modelo Árbol de Decisión:", accuracy_dtc)

# Extraer las características "Compras" y "Promedio"
compras = df["COMP"]
promedio = df["PROM"]

# Crear la gráfica de dispersión
plt.figure(figsize=(8, 6))
plt.scatter(compras, promedio, color='blue', alpha=0.5)
plt.title('Gráfica de dispersión entre Compras y Promedio')
plt.xlabel('COMP')
plt.ylabel('PROM')
plt.grid(True)
plt.show()

df.info()

jb.dump(gnb, 'modeloNB.bin')#modelo de Gaussian
jb.dump(rfc, 'ModeloBosque.bin')#modelo de bosque
jb.dump(dtc, 'ModeloArbol.bin')#modelo de arbol de deciciones

print("Modelos guardados exitosamente.")



modeloNB=GaussianNB()

modeloNB.fit(X_train,y_train)

y_train.value_counts()

from imblearn.under_sampling import RandomUnderSampler

rus=RandomUnderSampler(random_state=42, sampling_strategy= 'auto')

X_resampled, y_resampled = rus.fit_resample(X_train, y_train)

print(len(y_resampled))
print(y_resampled.value_counts())
y_resampled.plot.hist()

modelo_reen=GaussianNB()
modeloNB.fit(X_resampled,y_resampled)

jb.dump(modeloNB,"modeloNB2.bin",compress=True)

y_prect=modeloNB.predict(X_test)
y_prect

fpr,tpr,umbral=roc_curve(y_test,y_prect)
plt.plot(fpr,tpr)
plt.plot([0,1],[0,1],"--")
plt.xlabel("Tasa Falso Positivos")
plt.ylabel("Tasa de Verdaderos Positivos")
plt.title("CURVA ROC")
plt.show()

matrix=confusion_matrix(y_test,y_prect)
mostrarMatrix=ConfusionMatrixDisplay(confusion_matrix= matrix,display_labels=modeloNB.classes_)
mostrarMatrix.plot()



print(classification_report(y_test,y_prect))

print(classification_report(y_test,y_prect))

print("Area bajo la curva",auc(fpr,tpr))

Kpliegues=KFold(n_splits=5)
scores=cross_val_score(modeloNB,X_train,y_train,cv=Kpliegues)
print("Score Naive Bayes con Cross Validation",scores)
print("Promedio de los Scores",scores.mean())
print("Varianza de los Scores",scores.var())
print("Número de Pliegues Usados",len(scores))

cross_val_predict(modeloNB,X_train,y_train,cv=Kpliegues)

y_train

"""##Balancear los Datos"""

y_train.plot.hist()

y_train.value_counts()

from imblearn.under_sampling import RandomUnderSampler





y_test.values

modeloNB.score(X_test,y_test)

print(classification_report(y_test,y_prect))

fpr,tpr,umbral=roc_curve(y_test,y_prect)
plt.plot(fpr,tpr)
plt.plot([0,1],[0,1],"--")
plt.xlabel("Tasa Falso Positivos")
plt.ylabel("Tasa de Verdaderos Positivos")
plt.title("CURVA ROC")
plt.show()

print("Area bajo la curva",auc(fpr,tpr))

matrix=confusion_matrix(y_test,y_prect)
print(matrix)
mostrarMatrix=ConfusionMatrixDisplay(confusion_matrix=matrix,display_labels=modeloNB.classes_)
mostrarMatrix.plot()

cm_gnb = confusion_matrix(y_test, y_pred_gnb)

# Visualizar la matriz de confusión para Gaussian Naive Bayes
plt.figure(figsize=(8, 6))
sns.heatmap(cm_gnb, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Matriz de Confusión - Gaussian Naive Bayes")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# Calcular la matriz de confusión para Random Forest
cm_rfc = confusion_matrix(y_test, y_pred_rfc)

# Visualizar la matriz de confusión para Random Forest
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rfc, annot=True, fmt="d", cmap="Greens", cbar=False)
plt.title("Matriz de Confusión - Random Forest")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# Calcular la matriz de confusión para Árbol de Decisión
cm_dtc = confusion_matrix(y_test, y_pred_dtc)

# Visualizar la matriz de confusión para Árbol de Decisión
plt.figure(figsize=(8, 6))
sns.heatmap(cm_dtc, annot=True, fmt="d", cmap="Oranges", cbar=False)
plt.title("Matriz de Confusión - Árbol de Decisión")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

#matrix de confusión para analizar los errores de predicción
matrix=confusion_matrix(y_test,y_pred_dtc,labels=modeloNB.classes_)
displaymatrix=ConfusionMatrixDisplay(confusion_matrix=matrix,display_labels=modeloNB.classes_)
displaymatrix.plot(xticks_rotation='vertical')

from sklearn import tree

modeloArbol = tree.DecisionTreeClassifier()
modeloArbol.fit(X_train, y_train)

#accuracy del set de entrenamiento

modeloArbol.score(X_train,y_train)*100

#accuracy del set de prueba
#accuracy_score(y_test,y_predict)

modeloArbol.score(X_test,y_test)*100
X_test

#confusion_matrix con los datos de prueba
y_predict=modeloArbol.predict(X_test)
print(y_test.head(20))
print(pd.DataFrame(y_predict).head(20))

#matrix de confusión para analizar los errores de predicción
matrix=confusion_matrix(y_test,y_predict,labels=modeloArbol.classes_)
displaymatrix=ConfusionMatrixDisplay(confusion_matrix=matrix,display_labels=modeloArbol.classes_)
displaymatrix.plot(xticks_rotation='vertical')

print(classification_report(y_test,y_predict))

#tree.plot_tree(modeloArbol)
tree.plot_tree(modeloArbol)
plt.show()

df.head()